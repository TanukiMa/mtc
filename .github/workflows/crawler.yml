name: åšåŠ´çœã‚µã‚¤ãƒˆå°‚é–€ç”¨èªè§£æ (SudachiDict-full)

on:
  schedule:
    # æ¯æ—¥åˆå‰2æ™‚ï¼ˆJST 11æ™‚ï¼‰ã«å®Ÿè¡Œ
    - cron: '0 2 * * *'
  workflow_dispatch:  # æ‰‹å‹•å®Ÿè¡Œã‚‚å¯èƒ½
    inputs:
      max_workers:
        description: 'ä¸¦åˆ—å‡¦ç†æ•°'
        required: false
        default: '3'
        type: string

env:
  PYTHON_VERSION: '3.11'
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}

jobs:
  analyze-mhlw-terms:
    runs-on: ubuntu-latest
    timeout-minutes: 180  # SudachiDict-fullã‚’è€ƒæ…®ã—ã¦3æ™‚é–“ã«å»¶é•·
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install system dependencies (minimal for package installation)
      run: |
        sudo apt-get update
        # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹å¼ã®ãŸã‚ã€build toolsã¯ä¸è¦
        echo "â„¹ï¸  ã‚·ã‚¹ãƒ†ãƒ ä¾å­˜é–¢ä¿‚ã¯æœ€å°é™ï¼ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹å¼ï¼‰"
    
    - name: Install Python dependencies (including SudachiDict-full)
      run: |
        python -m pip install --upgrade pip
        
        echo "ğŸ“¦ Pythonä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­..."
        pip install \
          requests==2.31.0 \
          beautifulsoup4==4.12.2 \
          supabase==2.0.2 \
          sudachipy==0.6.7 \
          huggingface_hub==0.19.4 \
          python-docx==0.8.11 \
          python-pptx==0.6.22 \
          PyPDF2==3.0.1 \
          lxml==4.9.3
        
        echo "ğŸ“š Sudachiè¾æ›¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­..."
        echo "â° Fullè¾æ›¸ã¯å¤§å®¹é‡ã®ãŸã‚ã€2-3åˆ†ã‹ã‹ã‚Šã¾ã™..."
        
        # Coreè¾æ›¸ã‚‚ä¸€ç·’ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
        pip install sudachidict_core
        # Fullè¾æ›¸ã‚’ãƒ¡ã‚¤ãƒ³è¾æ›¸ã¨ã—ã¦ä½¿ç”¨
        pip install SudachiDict-full
        
        echo "âœ… ã™ã¹ã¦ã®ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†"
    
    - name: Install llama.cpp from Debian sid (with GPG fix)
      run: |
        echo "ğŸ”§ llama.cpp ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­ï¼ˆDebian sid ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰ï¼‰"
        
        # Debian GPGã‚­ãƒ¼ã‚’è¿½åŠ ï¼ˆç½²åæ¤œè¨¼ã®ãŸã‚ï¼‰
        echo "ğŸ”‘ Debian GPGã‚­ãƒ¼è¿½åŠ ä¸­..."
        sudo apt-get install -y gnupg
        
        # Debianå…¬å¼GPGã‚­ãƒ¼ã‚’è¿½åŠ 
        wget -qO- https://ftp-master.debian.org/keys/archive-key-12.asc | sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/debian-archive-keyring.gpg
        wget -qO- https://ftp-master.debian.org/keys/archive-key-12-security.asc | sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/debian-archive-keyring-security.gpg
        
        # sidãƒªãƒã‚¸ãƒˆãƒªè¿½åŠ 
        echo "ğŸ“¦ Debian sidãƒªãƒã‚¸ãƒˆãƒªè¿½åŠ ä¸­..."
        echo "deb http://deb.debian.org/debian sid main" | sudo tee /etc/apt/sources.list.d/sid.list
        
        # å„ªå…ˆåº¦è¨­å®šï¼ˆsidã‹ã‚‰ã¯å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã¿ï¼‰
        sudo tee /etc/apt/preferences.d/llama-cpp-pin << 'EOF'
        Package: llama.cpp
        Pin: release a=sid
        Pin-Priority: 500

        Package: *
        Pin: release a=sid
        Pin-Priority: 100
        EOF
        
        # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒªã‚¹ãƒˆæ›´æ–°
        echo "ğŸ”„ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒªã‚¹ãƒˆæ›´æ–°ä¸­..."
        if ! sudo apt update; then
            echo "âš ï¸  GPGç½²åã‚¨ãƒ©ãƒ¼ãŒç¶™ç¶šã™ã‚‹å ´åˆã€ã‚½ãƒ¼ã‚¹ãƒ“ãƒ«ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚½ãƒ¼ã‚¹ãƒ“ãƒ«ãƒ‰
            echo "ğŸ› ï¸  llama.cpp ã‚½ãƒ¼ã‚¹ãƒ“ãƒ«ãƒ‰ã‚’å®Ÿè¡Œä¸­..."
            sudo apt-get install -y build-essential cmake
            
            git clone --depth 1 https://github.com/ggerganov/llama.cpp.git /tmp/llama.cpp
            cd /tmp/llama.cpp
            make -j$(nproc) LLAMA_NO_ACCELERATE=1
            sudo cp main /usr/local/bin/llama-cli
            sudo cp server /usr/local/bin/llama-server
            echo "LLAMA_CLI_PATH=/usr/local/bin/llama-cli" >> $GITHUB_ENV
            echo "âœ… llama.cpp ã‚½ãƒ¼ã‚¹ãƒ“ãƒ«ãƒ‰å®Œäº†"
            
        else
            # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æˆåŠŸã®å ´åˆ
            echo "ğŸ“¦ llama.cpp ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­..."
            if sudo apt install -y llama.cpp; then
                echo "LLAMA_CLI_PATH=llama-cli" >> $GITHUB_ENV
                echo "âœ… llama.cpp ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†"
            else
                echo "âŒ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¤±æ•—ã€ã‚½ãƒ¼ã‚¹ãƒ“ãƒ«ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"
                
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
                sudo apt-get install -y build-essential cmake
                git clone --depth 1 https://github.com/ggerganov/llama.cpp.git /tmp/llama.cpp
                cd /tmp/llama.cpp
                make -j$(nproc) LLAMA_NO_ACCELERATE=1
                sudo cp main /usr/local/bin/llama-cli
                sudo cp server /usr/local/bin/llama-server
                echo "LLAMA_CLI_PATH=/usr/local/bin/llama-cli" >> $GITHUB_ENV
                echo "âœ… llama.cpp ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ“ãƒ«ãƒ‰å®Œäº†"
            fi
        fi
        
        # å‹•ä½œç¢ºèª
        echo "ğŸ§ª llama-cli å‹•ä½œç¢ºèª:"
        $LLAMA_CLI_PATH --help | head -5 || echo "ãƒã‚¤ãƒŠãƒªãƒ‘ã‚¹ã‚’ç¢ºèªä¸­..."
        
        # ãƒ‘ã‚¹ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        which llama-cli >/dev/null 2>&1 && echo "âœ… llama-cli found in PATH" || echo "â„¹ï¸  llama-cli custom path: $LLAMA_CLI_PATH"
    
    - name: Download LLM model with huggingface-cli
      run: |
        echo "ğŸ¤– æ—¥æœ¬èªLLMãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."
        mkdir -p models
        
        # æ—¥æœ¬èªå¯¾å¿œã®è»½é‡ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        huggingface-cli download \
          mmnga/ELYZA-japanese-Llama-2-7b-fast-instruct-gguf \
          ELYZA-japanese-Llama-2-7b-fast-instruct-q4_0.gguf \
          --local-dir models \
          --local-dir-use-symlinks False
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«åã‚’çµ±ä¸€
        mv models/ELYZA-japanese-Llama-2-7b-fast-instruct-q4_0.gguf models/ggml-model-Q4_K_M.gguf
        
        echo "LLAMA_MODEL_PATH=$(pwd)/models/ggml-model-Q4_K_M.gguf" >> $GITHUB_ENV
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
        echo "ğŸ“Š ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†:"
        ls -lh models/ggml-model-Q4_K_M.gguf
        echo "âœ… LLMãƒ¢ãƒ‡ãƒ«æº–å‚™å®Œäº†"
    
    - name: Setup and Test SudachiDict-full
      run: |
        echo "ğŸ”¤ SudachiDict-full è¨­å®šãƒ»å‹•ä½œç¢ºèªãƒ»ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"
        
        # SudachiPyè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼ˆFullè¾æ›¸æŒ‡å®šï¼‰
        mkdir -p ~/.sudachi
        python -c "
        import json
        import os
        from pathlib import Path
        
        # SudachiDict-fullã®ãƒ‘ã‚¹ã‚’æ¢ã™
        try:
            import sudachidict_full
            full_dict_path = Path(sudachidict_full.__file__).parent / 'resources' / 'system.dic'
            print(f'ğŸ“ SudachiDict-full ãƒ‘ã‚¹: {full_dict_path}')
        except ImportError:
            print('âš ï¸  SudachiDict-fullãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š
            full_dict_path = None
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        config = {
            'systemDict': str(full_dict_path) if full_dict_path and full_dict_path.exists() else None,
            'characterDefinitionFile': 'char.def',
            'inputTextPlugin': [],
            'oovProviderPlugin': [],
            'pathRewritePlugin': [],
            'connectPlugin': []
        }
        
        config_path = Path.home() / '.sudachi' / 'sudachi.json'
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        print(f'ğŸ“„ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {config_path}')
        "
        
        # å‹•ä½œç¢ºèªã¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        python -c "
        import time
        from sudachipy import tokenizer, dictionary
        
        print('ğŸš€ SudachiDict-full åˆæœŸåŒ–ä¸­...')
        start_time = time.time()
        
        try:
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¦è¾æ›¸åˆæœŸåŒ–
            tokenizer_obj = dictionary.Dictionary().create()
            init_time = time.time() - start_time
            print(f'â±ï¸  åˆæœŸåŒ–å®Œäº†: {init_time:.2f}ç§’')
            
            # åšåŠ´çœãƒ»åŒ»ç™‚é–¢é€£ã®å°‚é–€ç”¨èªã§ãƒ†ã‚¹ãƒˆ
            test_cases = [
                'åšç”ŸåŠ´åƒçœã®æ–°ã—ã„æ–½ç­–ã«ã¤ã„ã¦',
                'ãƒ†ãƒ¬ãƒ¡ãƒ‡ã‚£ã‚·ãƒ³ã«ã‚ˆã‚‹é éš”è¨ºç™‚',
                'ãƒ¬ã‚»ãƒ—ãƒˆé›»ç®—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ',
                'è¨ºç™‚å ±é…¬ç‚¹æ•°è¡¨ã®æ”¹å®š',
                'åŒ»ç™‚DXæ¨é€²æœ¬éƒ¨',
                'PHRï¼ˆPersonal Health Recordï¼‰',
                'åœ°åŸŸåŒ…æ‹¬ã‚±ã‚¢ã‚·ã‚¹ãƒ†ãƒ ',
                'è–¬äº‹ãƒ»é£Ÿå“è¡›ç”Ÿå¯©è­°ä¼š'
            ]
            
            print('\\nğŸ“ å°‚é–€ç”¨èªè§£æãƒ†ã‚¹ãƒˆçµæœ:')
            print('=' * 50)
            
            total_tokens = 0
            for i, text in enumerate(test_cases, 1):
                start = time.time()
                tokens = tokenizer_obj.tokenize(text, tokenizer.Tokenizer.SplitMode.A)
                parse_time = time.time() - start
                total_tokens += len(tokens)
                
                print(f'\\n{i}. ã€Œ{text}ã€')
                print(f'   è§£ææ™‚é–“: {parse_time*1000:.1f}ms | ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {len(tokens)}')
                print('   å½¢æ…‹ç´ è§£æçµæœ:')
                
                for token in tokens:
                    surface = token.surface()
                    reading = token.reading_form() or 'ãƒ¼ãƒ¼'
                    pos = token.part_of_speech()[0]
                    
                    # å°‚é–€ç”¨èªã‚‰ã—ã„ã‚‚ã®ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
                    if pos == 'åè©' and len(surface) >= 3:
                        print(f'   ğŸ” {surface} ({reading}) [{pos}] â† å°‚é–€ç”¨èªå€™è£œ')
                    else:
                        print(f'     {surface} ({reading}) [{pos}]')
            
            print(f'\\nâœ… SudachiDict-full ãƒ†ã‚¹ãƒˆå®Œäº†')
            print(f'ğŸ“Š ç·è§£æ: {len(test_cases)}æ–‡ / {total_tokens}ãƒˆãƒ¼ã‚¯ãƒ³')
            print('ğŸ¯ å°‚é–€ç”¨èªã®è©³ç´°ãªåˆ†å‰²ãƒ»èª­ã¿å–ã‚ŠãŒç¢ºèªã§ãã¾ã—ãŸ')
            
        except Exception as e:
            print(f'âŒ SudachiDict-full åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}')
            print('ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¾æ›¸ã‚’ä½¿ç”¨ã—ã¾ã™')
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
            tokenizer_obj = dictionary.Dictionary().create()
            tokens = tokenizer_obj.tokenize('åšç”ŸåŠ´åƒçœ', tokenizer.Tokenizer.SplitMode.A)
            print(f'âœ… ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¾æ›¸ã§å‹•ä½œç¢ºèªå®Œäº† ({len(tokens)}ãƒˆãƒ¼ã‚¯ãƒ³)')
        "
        
        echo "ğŸ“š ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿è¾æ›¸ç¢ºèª:"
        pip list | grep -i sudachi
    
    - name: Create cache directories
      run: |
        mkdir -p ~/.cache/sudachi
        mkdir -p /tmp
        echo "ğŸ“ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆå®Œäº†"
    
    - name: Verify complete environment
      run: |
        echo "ğŸ” ç’°å¢ƒç¢ºèªãƒ»å‹•ä½œæ¤œè¨¼"
        echo "=========================="
        
        echo "ğŸ Pythonç’°å¢ƒ:"
        python --version
        
        echo "ğŸ¤– llama-cliç¢ºèª:"
        if command -v llama-cli >/dev/null 2>&1; then
            echo "âœ… llama-cli found in PATH"
            llama-cli --version 2>/dev/null || llama-cli --help | head -3
        elif [ -f "/usr/local/bin/llama-cli" ]; then
            echo "âœ… llama-cli found at /usr/local/bin/llama-cli (source build)"
            /usr/local/bin/llama-cli --version 2>/dev/null || /usr/local/bin/llama-cli --help | head -3
        else
            echo "âŒ llama-cli not found"
            exit 1
        fi
        
        echo "ğŸ”¤ SudachiPy + Fullè¾æ›¸ æœ€çµ‚ç¢ºèª:"
        python -c "
        from sudachipy import dictionary
        import os
        tokenizer_obj = dictionary.Dictionary().create()
        # ç°¡å˜ãªãƒ†ã‚¹ãƒˆ
        tokens = tokenizer_obj.tokenize('åšåŠ´çœ', 1)
        print(f'âœ… SudachiDict-full æº–å‚™å®Œäº† (ãƒ†ã‚¹ãƒˆ: {len(tokens)}ãƒˆãƒ¼ã‚¯ãƒ³)')
        "
        
        echo "ğŸ—„ï¸ Supabaseæ¥ç¶šç¢ºèª:"
        echo "SUPABASE_URL: ${SUPABASE_URL:0:30}..."
        
        echo "ğŸ¤– LLMãƒ¢ãƒ‡ãƒ«ç¢ºèª:"
        echo "Model path: $LLAMA_MODEL_PATH"
        echo "CLI path: $LLAMA_CLI_PATH"
        if [ -f "$LLAMA_MODEL_PATH" ]; then
            file "$LLAMA_MODEL_PATH"
        else
            echo "âŒ Model file not found: $LLAMA_MODEL_PATH"
        fi
        
        echo "ğŸ“¦ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«çŠ¶æ³:"
        # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç‰ˆã®ç¢ºèª
        if dpkg -l | grep -q llama; then
            echo "âœ… llama.cpp package installed:"
            dpkg -l | grep llama
        else
            echo "â„¹ï¸  llama.cpp installed via source build"
        fi
        
        # SudachiDictç¢ºèª
        echo "ğŸ“š Sudachiè¾æ›¸ç¢ºèª:"
        pip list | grep -i sudachi
        
        echo "âœ… ç’°å¢ƒæ¤œè¨¼å®Œäº† - ã™ã¹ã¦æ­£å¸¸"
    
    - name: Initialize Supabase dictionary (basic words)
      run: |
        echo "ğŸ—„ï¸ Supabase åŸºæœ¬è¾æ›¸åˆæœŸåŒ–"
        
        python3 << 'EOF'
        import os
        from supabase import create_client
        
        print("ğŸ“¡ Supabaseæ¥ç¶šä¸­...")
        client = create_client(os.environ['SUPABASE_URL'], os.environ['SUPABASE_KEY'])
        
        # åšåŠ´çœãƒ»åŒ»ç™‚åˆ†é‡ã®åŸºæœ¬è¾æ›¸èªå½™
        basic_words = [
            {'word': 'åŒ»ç™‚', 'reading': 'ã‚¤ãƒªãƒ§ã‚¦', 'part_of_speech': 'åè©', 'source': 'basic'},
            {'word': 'åšç”ŸåŠ´åƒçœ', 'reading': 'ã‚³ã‚¦ã‚»ã‚¤ãƒ­ã‚¦ãƒ‰ã‚¦ã‚·ãƒ§ã‚¦', 'part_of_speech': 'åè©', 'source': 'basic'},
            {'word': 'å¥åº·', 'reading': 'ã‚±ãƒ³ã‚³ã‚¦', 'part_of_speech': 'åè©', 'source': 'basic'},
            {'word': 'è¨ºç™‚', 'reading': 'ã‚·ãƒ³ãƒªãƒ§ã‚¦', 'part_of_speech': 'åè©', 'source': 'basic'},
            {'word': 'è–¬äº‹', 'reading': 'ãƒ¤ã‚¯ã‚¸', 'part_of_speech': 'åè©', 'source': 'basic'},
            {'word': 'ä¿é™º', 'reading': 'ãƒ›ã‚±ãƒ³', 'part_of_speech': 'åè©', 'source': 'basic'},
            {'word': 'ä»‹è­·', 'reading': 'ã‚«ã‚¤ã‚´', 'part_of_speech': 'åè©', 'source': 'basic'},
            {'word': 'ç¦ç¥‰', 'reading': 'ãƒ•ã‚¯ã‚·', 'part_of_speech': 'åè©', 'source': 'basic'}
        ]
        
        try:
            # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
            existing = client.table('dictionary_words').select('word').limit(1).execute()
            if not existing.data:
                client.table('dictionary_words').insert(basic_words).execute()
                print(f"âœ… åŸºæœ¬è¾æ›¸ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ ({len(basic_words)}èª)")
            else:
                print("â„¹ï¸  è¾æ›¸ã¯æ—¢ã«åˆæœŸåŒ–æ¸ˆã¿ã§ã™")
            
            # çµ±è¨ˆæƒ…å ±
            total_dict_words = client.table('dictionary_words').select('id', count='exact').execute()
            print(f"ğŸ“Š ç¾åœ¨ã®è¾æ›¸èªå½™æ•°: {total_dict_words.count}èª")
            
        except Exception as e:
            print(f"âš ï¸  è¾æ›¸åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
        EOF
        
        echo "âœ… Supabaseè¾æ›¸åˆæœŸåŒ–å®Œäº†"
    
    - name: Run MHLW crawler with SudachiDict-full
      env:
        MAX_WORKERS: ${{ github.event.inputs.max_workers || '3' }}
      run: |
        echo "ğŸš€ åšåŠ´çœã‚µã‚¤ãƒˆè§£æã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼å®Ÿè¡Œé–‹å§‹"
        echo "è¨­å®š:"
        echo "  - ä¸¦åˆ—å‡¦ç†æ•°: $MAX_WORKERS"
        echo "  - è¾æ›¸: SudachiDict-full (170ä¸‡èª)"
        echo "  - å¯¾è±¡: åšåŠ´çœã‚µã‚¤ãƒˆï¼ˆHTML, PDF, DOCX, PPTXï¼‰"
        
        python3 << 'EOF'
        import sys
        import os
        import traceback
        from datetime import datetime
        
        sys.path.append('.')
        
        print(f"ğŸ•’ é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            from main_crawler import MhlwCrawler
            
            print("ğŸ”§ ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼åˆæœŸåŒ–ä¸­...")
            crawler = MhlwCrawler()
            
            max_workers = int(os.environ.get('MAX_WORKERS', '3'))
            print(f"ğŸ‘¥ ä¸¦åˆ—å‡¦ç†æ•°: {max_workers}")
            
            print("ğŸ“¡ ã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°ãƒ»è§£æé–‹å§‹...")
            crawler.run(max_workers=max_workers)
            
            print(f"ğŸ•’ å®Œäº†æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print("âœ… åšåŠ´çœã‚µã‚¤ãƒˆè§£æå®Œäº†")
            
        except Exception as e:
            print(f"âŒ ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
            sys.exit(1)
        EOF
    
    - name: Generate detailed analysis report
      if: always()
      run: |
        echo "ğŸ“Š è§£æçµæœãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­..."
        
        python3 << 'EOF'
        import os
        from supabase import create_client
        from datetime import datetime, timedelta
        
        client = create_client(os.environ['SUPABASE_URL'], os.environ['SUPABASE_KEY'])
        
        # ä»Šæ—¥ã®çµæœã‚µãƒãƒªãƒ¼
        today = datetime.now().date()
        
        print("ğŸ“ˆ åšåŠ´çœã‚µã‚¤ãƒˆå°‚é–€ç”¨èªè§£æçµæœ")
        print("=" * 50)
        print(f"ğŸ•’ å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ”¤ ä½¿ç”¨è¾æ›¸: SudachiDict-full (170ä¸‡èª)")
        print("")
        
        # æ–°èªå€™è£œæ•°
        try:
            new_words = client.table('new_word_candidates')\
                .select('*')\
                .gte('created_at', today.isoformat())\
                .execute()
            
            # å‡¦ç†URLæ•°
            processed = client.table('processed_urls')\
                .select('*')\
                .gte('created_at', today.isoformat())\
                .execute()
            
            # æŠ½å‡ºã•ã‚ŒãŸå…¨å˜èªæ•°
            extracted = client.table('extracted_words')\
                .select('*')\
                .gte('first_found', today.isoformat())\
                .execute()
            
            print(f"ğŸ“„ å‡¦ç†æ¸ˆURL: {len(processed.data)}ä»¶")
            print(f"ğŸ”¤ æŠ½å‡ºå˜èª: {len(extracted.data)}èª")
            print(f"ğŸ†• æ–°èªå€™è£œ: {len(new_words.data)}èª")
            
            if new_words.data:
                print(f"ğŸ“Š æ–°èªç™ºè¦‹ç‡: {len(new_words.data)/max(len(extracted.data),1)*100:.1f}%")
                
                print("\\nğŸ” ç™ºè¦‹ã•ã‚ŒãŸæ–°èªå€™è£œ TOP 10:")
                print("-" * 40)
                
                # ä¿¡é ¼åº¦ã§ã‚½ãƒ¼ãƒˆ
                sorted_words = sorted(new_words.data, 
                                    key=lambda x: x.get('confidence_score', 0), 
                                    reverse=True)
                
                for i, word in enumerate(sorted_words[:10], 1):
                    word_text = word.get('word', 'N/A')
                    reading = word.get('reading', 'ä¸æ˜')
                    confidence = word.get('confidence_score', 0)
                    pos = word.get('part_of_speech', 'ä¸æ˜')
                    reasoning = word.get('llm_reasoning', 'ç†ç”±ä¸æ˜')[:50]
                    
                    print(f"{i:2d}. {word_text} ({reading})")
                    print(f"    å“è©: {pos} | ä¿¡é ¼åº¦: {confidence:.3f}")
                    print(f"    ç†ç”±: {reasoning}...")
                    print()
            else:
                print("â„¹ï¸  ä»Šå›ã®å®Ÿè¡Œã§ã¯æ–°èªå€™è£œã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
            # è¾æ›¸çµ±è¨ˆ
            total_dict = client.table('dictionary_words').select('id', count='exact').execute()
            print(f"ğŸ“š ç¾åœ¨ã®è¾æ›¸èªå½™æ•°: {total_dict.count:,}èª")
            
        except Exception as e:
            print(f"âš ï¸  ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
        
        print("\\nâœ… è§£æå®Œäº†")
        print("ğŸ¯ SudachiDict-fullã«ã‚ˆã‚‹é«˜ç²¾åº¦å°‚é–€ç”¨èªè§£æãŒå®Œäº†ã—ã¾ã—ãŸ")
        EOF
    
    - name: Cleanup and optimize storage
      if: always()
      run: |
        echo "ğŸ§¹ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œä¸­..."
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        rm -rf /tmp/*.pdf /tmp/*.docx /tmp/*.pptx /tmp/*.txt
        
        # pip ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ï¼ˆå®¹é‡ç¯€ç´„ï¼‰
        pip cache purge
        
        # modelsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ä¿æŒï¼ˆæ¬¡å›å®Ÿè¡Œæ™‚ã®å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å›é¿ï¼‰
        echo "ğŸ’¾ LLMãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä¿æŒï¼ˆå†åˆ©ç”¨ã®ãŸã‚ï¼‰"
        
        # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ç¢ºèª
        echo "ğŸ’½ ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡:"
        df -h | head -2
        
        echo "âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†"
    
    - name: Upload comprehensive logs
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: mhlw-crawler-logs-${{ github.run_id }}
        path: |
          *.log
          /tmp/crawler_*.txt
          /tmp/sudachi_*.log
          /var/log/syslog
        retention-days: 14
        if-no-files-found: ignore
