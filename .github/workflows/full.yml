name: Local DB Pipeline (Discover, Preprocess, Process, Sync)

on:
  workflow_dispatch:
    inputs:
      debug_preprocess:
        description: 'Run preprocessor in debug mode (generates CSV artifact)'
        required: false
        type: boolean
        default: false

jobs:
  run_pipeline:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_USER: runner
          POSTGRES_PASSWORD: password
          POSTGRES_DB: localdb
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install all dependencies
        run: |
          sudo apt-get update && sudo apt-get install -yf libpq-dev postgresql-client
          pip install -r requirements.txt

      - name: Wait for PostgreSQL
        env:
          PGPASSWORD: password
        run: |
          until pg_isready -h localhost -p 5432 -U runner; do
            echo "Waiting for PostgreSQL..."
            sleep 2
          done
          echo "PostgreSQL is ready!"

      - name: 1. Initialize Local Database
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          LOCAL_DB_URL: "postgresql://runner:password@localhost:5432/localdb"
        run: python init_local_db.py

      - name: 2. Run URL Discoverer
        env:
          LOCAL_DB_URL: "postgresql://runner:password@localhost:5432/localdb"
        run: python discover_urls.py
      
      - name: 3. Run Preprocessor
        env:
          LOCAL_DB_URL: "postgresql://runner:password@localhost:5432/localdb"
        run: |
          if [[ "${{ github.event.inputs.debug_preprocess }}" == "true" ]]; then
            echo "Running preprocessor in debug mode..."
            python preprocess.py --debug
          else
            echo "Running preprocessor in production mode..."
            python preprocess.py
          fi

      - name: Upload Preprocess Debug Log
        if: ${{ github.event.inputs.debug_preprocess == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: preprocess-debug-log-${{ github.run_id }}
          path: preprocess_debug_output.csv

      - name: 4. Run NLP Processors in Parallel
        env:
          LOCAL_DB_URL: "postgresql://runner:password@localhost:5432/localdb"
        run: |
          python process_ginza.py &
          python process_stanza.py &
          wait

      - name: 5. Dump Local Database and Upload Artifact
        env:
          PGPASSWORD: password
        run: |
          echo "Dumping local database to local_db_dump.sql..."
          pg_dump --clean --if-exists -h localhost -p 5432 -U runner -d localdb > local_db_dump.sql
          echo "Dump complete."
      
      - name: Upload database dump as artifact
        uses: actions/upload-artifact@v4
        with:
          name: database-dump-${{ github.run_id }}
          path: local_db_dump.sql

      - name: 6. Sync Results to Supabase
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          LOCAL_DB_URL: "postgresql://runner:password@localhost:5432/localdb"
        run: python sync_to_supabase.py